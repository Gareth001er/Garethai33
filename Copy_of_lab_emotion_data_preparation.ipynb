{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gareth001er/Garethai33/blob/main/Copy_of_lab_emotion_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e647a813",
      "metadata": {
        "id": "e647a813"
      },
      "source": [
        "# Emotion Classification: Data Preparation\n",
        "\n",
        "In this notebook, you'll:\n",
        "\n",
        "- Upload up to 10 face images per emotion class.\n",
        "- Organize them into folders by emotion.\n",
        "- Split the dataset into training and testing sets.\n",
        "\n",
        "**Emotions to capture:** `['happy', 'sad', 'angry', 'surprised', 'neutral']`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c308b1",
      "metadata": {
        "id": "15c308b1"
      },
      "source": [
        "## 1. Setup and Imports\n",
        "Install dependencies and import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eac6d8f",
      "metadata": {
        "id": "6eac6d8f"
      },
      "outputs": [],
      "source": [
        "#sample\n",
        "#!pip install scikit-learn pandas\n",
        "#import os\n",
        "#from google.colab import files\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import pandas as pd\n",
        "\n",
        "# Emotion classes\n",
        "#emotions = ['happy', 'sad', 'angry', 'surprised', 'neutral']\n",
        "#data_dir = 'data'\n",
        "\n",
        "# Create data directories\n",
        "#os.makedirs(data_dir, exist_ok=True)\n",
        "#for emo in emotions:\n",
        "    #os.makedirs(os.path.join(data_dir, emo), exist_ok=True)\n",
        "#print(\"Setup complete. Data directories ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAbH2GqYicup",
        "outputId": "748a27da-ba1a-40ad-9370-f9b6c11f8371"
      },
      "id": "ZAbH2GqYicup",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4077c610",
      "metadata": {
        "id": "4077c610"
      },
      "source": [
        "## 2. Upload Images per Emotion\n",
        "For each emotion, upload up to 10 images. After selecting files, the dialog will close."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49008c52",
      "metadata": {
        "id": "49008c52"
      },
      "source": [
        "## 3. Prepare Train/Test Split\n",
        "Gather all image paths and labels, then split:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe37874",
      "metadata": {
        "id": "7fe37874"
      },
      "source": [
        "## 4. Save Split Lists\n",
        "Export file lists and labels to CSV for future use:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aswer reflection in markdown\n",
        "\n",
        "1. **Hidden Bias:**  \n",
        "   Identify one scenario where your current images might lead the model to learn a spurious signal (e.g. background, lighting). How would you test for and eliminate it?\n",
        "\n",
        "2. **Edge Cases:**  \n",
        "   Describe a face or expression that your dataset likely fails to capture. What impact could that have on real-world performance, and how would you address it?\n",
        "\n",
        "3. **Generalization Strategy:**  \n",
        "   With only 10 images per class, what’s one concrete augmentation or data-collection strategy you’d use to improve robustness—and why that choice?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kw96bB7LIlYw"
      },
      "id": "Kw96bB7LIlYw"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}